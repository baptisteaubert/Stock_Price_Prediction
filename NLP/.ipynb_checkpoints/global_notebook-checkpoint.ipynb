{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data fo NLP \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sys.executable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SEC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&CIK=0000789019&type=10-K&dateb=2017&owner=exclude&output=xml&count=100&output=xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/baptisteaubert/Environments/py3_stock_price_prediction/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html5lib\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"html5lib\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.sec.gov//Archives/edgar/data/789019/000156459018019062/msft-10k_20180630.htm\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-e327610c439a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0mSecCrawler_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSecCrawler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Microsoft'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0mSecCrawler_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_10ks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2017\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Microsoft'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m \u001b[0mSecCrawler_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_in_mongoDB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-e327610c439a>\u001b[0m in \u001b[0;36msave_in_mongoDB\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mdiscussion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"I[a-zA-Z]{3}\\s+8[.:]\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mdate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'For the fiscal year ended'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'or'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'10_K'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdiscussion\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#le resultat qu'on veut c'est une collection 10-K avec {company:AAPL, date:2015, 10-K:super Iphone mais Ipod en baisse}\n",
    "#Shema de la base: base: SEC_Data, 10-K et 5-K sont des collections, chaque doc contient date, company, report \n",
    "\n",
    "#working for Apple, Micorosft, Google, Amazone, facebook, Berkshire, United Heatlh, Intel, Home Depot, \n",
    "#Not working for Ebay, IBM (not present), JP (split in different pages), Johnson (le premier c Item et en dessous les nombres\n",
    "#Not Exon (reference to other part), BAML (trois Itm7.), Wells Fargo  (un seul), Visa (le premier  c Item 7), \n",
    "#Not Chevron Pfizer: (reference), AT&T (reference), Verizon Reference\n",
    "import os \n",
    "import sys\n",
    "import re\n",
    "from pymongo import MongoClient\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "class SecCrawler():\n",
    "\n",
    "    def __init__(self, company):\n",
    "        client = MongoClient('localhost', 27017)\n",
    "        self.company = company\n",
    "        self.db = client['SEC_Datas']\n",
    "        self.collection = self.db[company]\n",
    "        self.correspondance = {'Apple':'0000320193', 'Microsoft':'0000789019', 'Google':'0001288776', 'IBM':'0000051143',\n",
    "                              'Amazone':'0001018724', 'ebay':'0001065088', 'STX':'0000354952', 'facebook':'0001326801', \n",
    "                              'J.P. Morgan':'0000019617', 'Berkshire Hath':'0001067983', 'Jhonson & Johnoson':'0000200406',\n",
    "                              'Exxon':'0000034088', 'BAML':'0000070858', 'Weels_Fargo':'0000072971', 'Visa':'0001403161',\n",
    "                              'United_Health':'0000731766', 'Chevron':'0000093410', 'Pfizer':'0000078003',\n",
    "                              'AT&T':'0000732717','Intel':'0000050863', 'Home_Depot':'0000354950', 'Verizon':'0000732712'}\n",
    "\n",
    "                    \n",
    "    def get_10ks(self, max_date, count, company):\n",
    "        count=100\n",
    "        cik = self.correspondance[self.company]\n",
    "        base_url = \"http://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&CIK=\"+str(cik)+\"&type=10-K&dateb=\"+str(max_date)+\"&owner=exclude&output=xml&count=\"+str(count)+'&output=xml'\n",
    "        print(base_url)\n",
    "        r = requests.get(base_url)\n",
    "        data = r.text\n",
    "        soup = BeautifulSoup(data) \n",
    "        link_list=[] \n",
    "        \n",
    "        for link in soup.find_all('filinghref'):\n",
    "            URL = link.string\n",
    "            link_list.append(URL) \n",
    "        self.link_list = link_list\n",
    "        #print(self.link_list)\n",
    "        #for year_links in self.link_list[:4]:\n",
    "            #save_in_mongoDB(year_links)\n",
    "        \n",
    "        \n",
    "    def save_in_mongoDB(self):\n",
    "        for year_links in self.link_list[:4]:\n",
    "            K_10_link = get_K_10_link(year_links)\n",
    "            print(K_10_link)\n",
    "            r=requests.get(K_10_link)\n",
    "            data = r.text\n",
    "            soup = BeautifulSoup(data)\n",
    "            \n",
    "            text = soup.getText(strip=True)\n",
    "            temp = re.split(\"I[a-zA-Z]{3}\\s+7[.:]\", text)[2]\n",
    "            discussion = re.split(\"I[a-zA-Z]{3}\\s+8[.:]\", temp)[0]\n",
    "            \n",
    "            date = text.split('For the fiscal year ended')[1].split('or')[0][-4:]\n",
    "            self.collection.insert_one({'date':date, '10_K':discussion})\n",
    "\n",
    "    \n",
    "def get_K_10_link(documents_link):\n",
    "    r = requests.get(documents_link)\n",
    "    data = r.text\n",
    "    soup = BeautifulSoup(data)\n",
    "    tables = soup.findAll('table')\n",
    "    table = tables[0]\n",
    "    return 'http://www.sec.gov/'+table.find('tr').nextSibling.nextSibling.find('td').nextSibling.nextSibling.nextSibling.nextSibling.find('a')['href']\n",
    "\n",
    "SecCrawler_object = SecCrawler('Microsoft')\n",
    "SecCrawler_object.get_10ks(2017, 100, 'Microsoft')\n",
    "SecCrawler_object.save_in_mongoDB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py3_Stock_Price_Prediction",
   "language": "python",
   "name": "py3_stock_price_prediction"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
